import torch
torch._dynamo.disable()
from transformers import AutoProcessor, Gemma3nForConditionalGeneration
import argparse
import os
import librosa
import numpy as np
from tqdm import tqdm
from evaluate import load
from datasets import load_from_disk
import pandas as pd
import jiwer
from pathlib import Path
from utils.config import DEFAULT_MODEL_PATH, DEFAULT_DATASET_DIR, OUTPUTS_DIR, get_device, get_dtype, MODEL_NAME, ensure_dirs


class Estimin3nASRInference:
    def __init__(self, model_path: str | os.PathLike | None = None):
        ensure_dirs()
        self.model_path = str(Path(model_path).expanduser()) if model_path else str(DEFAULT_MODEL_PATH)
        self.device = get_device()
        self.dtype = get_dtype(self.device)
        print(f"üìä –£—Å—Ç—Ä–æ–π—Å—Ç–≤–æ: {self.device} | –¢–∏–ø –¥–∞–Ω–Ω—ã—Ö: {self.dtype}")

        self.model = Gemma3nForConditionalGeneration.from_pretrained(
            self.model_path, trust_remote_code=True, torch_dtype=self.dtype,
            device_map={"": str(self.device)}, low_cpu_mem_usage=True,
            attn_implementation="eager",
        )
        self.processor = AutoProcessor.from_pretrained(
            self.model_path, trust_remote_code=True
        )
        self.model.eval()
    print(f"üöÄ –ú–æ–¥–µ–ª—å {MODEL_NAME} –∑–∞–≥—Ä—É–∂–µ–Ω–∞ –∏ –≥–æ—Ç–æ–≤–∞!\n")

    def transcribe_from_array(self, audio_array: np.ndarray, source_sampling_rate: int, max_new_tokens=256, temperature=0.1):
        if source_sampling_rate != 16000:
            audio_array = librosa.resample(y=audio_array, orig_sr=source_sampling_rate, target_sr=16000)
        
        audio_data = audio_array.astype('float32')

        messages = [
            {"role": "system", "content": [{"type": "text", "text": """–°—ñ–∑ “õ–∞–∑–∞“õ —Ç—ñ–ª—ñ–Ω–¥–µ–≥—ñ –∞—É–¥–∏–æ–Ω—ã –¥”ô–ª —Ç—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ü–∏—è–ª–∞–π—Ç—ã–Ω –º–∞–º–∞–Ω –∫”©–º–µ–∫—à—ñ—Å—ñ–∑. 


–ù”ô—Ç–∏–∂–µ—Å—ñ–Ω–¥–µ —Ç–µ–∫ —Ç–∞–∑–∞ “õ–∞–∑–∞“õ—à–∞ –º”ô—Ç—ñ–Ω –±–µ—Ä—ñ“£—ñ–∑."""}]},
            {"role": "user", "content": [{"type": "audio", "audio": audio_data}, {"type": "text", "text": "–û—Å—ã –∞—É–¥–∏–æ–Ω—ã —Ç—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ü–∏—è–ª–∞“£—ã–∑."}]}
        ]
        
        try:
            inputs = self.processor.apply_chat_template(
                messages, add_generation_prompt=True, tokenize=True, return_dict=True, return_tensors="pt",
            ).to(self.device)
            
            if 'input_features' in inputs:
                inputs['input_features'] = inputs['input_features'].to(self.dtype)
            for key in ['input_ids', 'attention_mask']:
                if key in inputs:
                    inputs[key] = inputs[key].long()
            
            generation_kwargs = {
                'max_new_tokens': max_new_tokens, 'do_sample': True if temperature > 0 else False, 'temperature': temperature,
                'pad_token_id': self.processor.tokenizer.eos_token_id, 'eos_token_id': self.processor.tokenizer.eos_token_id,
            }
            
            with torch.no_grad():
                outputs = self.model.generate(**inputs, **generation_kwargs)
            
            generated_tokens = outputs[0][inputs["input_ids"].shape[1]:]
            transcription = self.processor.tokenizer.decode(generated_tokens, skip_special_tokens=True)
            return transcription.strip()
        
        except Exception as e:
            print(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞–±–æ—Ç–∫–µ –∞—É–¥–∏–æ-–º–∞—Å—Å–∏–≤–∞: {e}")
            return ""


def print_comparison(sample_num, reference, hypothesis, show_metrics=True):
    """–ö—Ä–∞—Å–∏–≤—ã–π –≤—ã–≤–æ–¥ —Å—Ä–∞–≤–Ω–µ–Ω–∏—è —Ç–µ–∫—Å—Ç–æ–≤"""
    print(f"\n{'='*80}")
    print(f"üìù –°–≠–ú–ü–õ #{sample_num}")
    print(f"{'='*80}")
    print(f"üéØ –†–ï–ê–õ–¨–ù–´–ô –¢–ï–ö–°–¢:")
    print(f"   {reference}")
    print(f"\nü§ñ –¢–†–ê–ù–°–ö–†–ò–ü–¶–ò–Ø:")
    print(f"   {hypothesis}")
    
    if show_metrics:
        # –í—ã—á–∏—Å–ª—è–µ–º –º–µ—Ç—Ä–∏–∫–∏ –¥–ª—è –æ—Ç–¥–µ–ª—å–Ω–æ–≥–æ —Å—ç–º–ø–ª–∞
        sample_wer = jiwer.wer(reference, hypothesis)
        sample_cer = jiwer.cer(reference, hypothesis)
        print(f"\nüìä –ú–ï–¢–†–ò–ö–ò –î–õ–Ø –≠–¢–û–ì–û –°–≠–ú–ü–õ–ê:")
        print(f"   WER: {sample_wer:.4f} ({sample_wer*100:.2f}%)")
        print(f"   CER: {sample_cer:.4f} ({sample_cer*100:.2f}%)")
    
    print(f"{'='*80}")


def run_benchmark(asr_model, dataset_path, source_sampling_rate, max_tokens, temperature, 
                  output_file, detailed_output_file, show_examples=True, show_every=10):
    try:
        dataset = load_from_disk(dataset_path)['train']
    except FileNotFoundError:
        print(f"‚ùå –û—à–∏–±–∫–∞: –ø–∞–ø–∫–∞ —Å –¥–∞—Ç–∞—Å–µ—Ç–æ–º –Ω–µ –Ω–∞–π–¥–µ–Ω–∞ –ø–æ –ø—É—Ç–∏ {dataset_path}")
        return

    print(f"üîä –í–ê–ñ–ù–û: –ø—Ä–µ–¥–ø–æ–ª–∞–≥–∞–µ—Ç—Å—è, —á—Ç–æ –≤—Å–µ –∞—É–¥–∏–æ –≤ –¥–∞—Ç–∞—Å–µ—Ç–µ –∏–º–µ—é—Ç —á–∞—Å—Ç–æ—Ç—É {source_sampling_rate} –ì—Ü.")
    print(f"üëÅÔ∏è  –ü—Ä–∏–º–µ—Ä—ã –±—É–¥—É—Ç –ø–æ–∫–∞–∑—ã–≤–∞—Ç—å—Å—è –∫–∞–∂–¥—ã–µ {show_every} —Å—ç–º–ø–ª–æ–≤" if show_examples else "üëÅÔ∏è  –ü—Ä–∏–º–µ—Ä—ã –æ—Ç–∫–ª—é—á–µ–Ω—ã")
    
    references = []
    hypotheses = []
    results_data = [] 

    wer_metric = load("wer")
    cer_metric = load("cer")
    
    with open(output_file, 'w', encoding='utf-8') as f:
        f.write("sample_count\tWER\tCER\n")

        for i, sample in enumerate(tqdm(dataset, desc="üéõÔ∏è  –û–±—Ä–∞–±–æ—Ç–∫–∞ –∞—É–¥–∏–æ")):
            audio_array = sample['audio']['array']
            reference_text = sample.get('text') or sample.get('transcription')

            if audio_array is None or reference_text is None:
                continue
            
            reference_text = str(reference_text).lower()
            
            hypothesis_text = asr_model.transcribe_from_array(
                audio_array,
                source_sampling_rate=source_sampling_rate,
                max_new_tokens=max_tokens,
                temperature=temperature
            ).lower()

            references.append(reference_text)
            hypotheses.append(hypothesis_text)
            
            results_data.append({
                "sample_id": i + 1,
                "reference": reference_text,
                "hypothesis": hypothesis_text
            })
            
            # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º –ø—Ä–∏–º–µ—Ä—ã —Å–æ–≥–ª–∞—Å–Ω–æ –Ω–∞—Å—Ç—Ä–æ–π–∫–∞–º
            if show_examples and ((i + 1) % show_every == 0 or i == 0):
                print_comparison(i + 1, reference_text, hypothesis_text, show_metrics=True)
            
            # –°–æ—Ö—Ä–∞–Ω—è–µ–º –ø—Ä–æ–º–µ–∂—É—Ç–æ—á–Ω—ã–µ –º–µ—Ç—Ä–∏–∫–∏ –∫–∞–∂–¥—ã–µ 10 —Å—ç–º–ø–ª–æ–≤
            if (i + 1) % 10 == 0:
                wer_score = wer_metric.compute(predictions=hypotheses, references=references)
                cer_score = cer_metric.compute(predictions=hypotheses, references=references)
                f.write(f"{(i + 1)}\t{wer_score:.4f}\t{cer_score:.4f}\n")
                f.flush()
                
                # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º –ø—Ä–æ–º–µ–∂—É—Ç–æ—á–Ω—É—é —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É
                print(f"\nüìà –ü—Ä–æ–º–µ–∂—É—Ç–æ—á–Ω–∞—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –ø–æ—Å–ª–µ {i + 1} —Å—ç–º–ø–ª–æ–≤:")
                print(f"   –°—Ä–µ–¥–Ω–∏–π WER: {wer_score:.4f} ({wer_score*100:.2f}%)")
                print(f"   –°—Ä–µ–¥–Ω–∏–π CER: {cer_score:.4f} ({cer_score*100:.2f}%)")

    if not references:
        print("‚ùå –ù–µ –±—ã–ª–æ –æ–±—Ä–∞–±–æ—Ç–∞–Ω–æ –Ω–∏ –æ–¥–Ω–æ–≥–æ —Ñ–∞–π–ª–∞.")
        return

    print("\n‚úÖ –ë–µ–Ω—á–º–∞—Ä–∫ –∑–∞–≤–µ—Ä—à–µ–Ω. –†–∞—Å—á–µ—Ç –∏—Ç–æ–≥–æ–≤—ã—Ö –º–µ—Ç—Ä–∏–∫...")
    
    final_wer_score = wer_metric.compute(predictions=hypotheses, references=references)
    final_cer_score = cer_metric.compute(predictions=hypotheses, references=references)
    
    print(f"\n{'='*50}")
    print("üèÜ –§–ò–ù–ê–õ–¨–ù–´–ï –†–ï–ó–£–õ–¨–¢–ê–¢–´")
    print(f"{'='*50}")
    print(f"üìä –í—Å–µ–≥–æ –æ–±—Ä–∞–±–æ—Ç–∞–Ω–æ —Å—ç–º–ø–ª–æ–≤: {len(references)}")
    print(f"üî° WER (Word Error Rate):     {final_wer_score:.4f} ({final_wer_score*100:.2f}%)")
    print(f"üî§ CER (Character Error Rate): {final_cer_score:.4f} ({final_cer_score*100:.2f}%)")
    print(f"{'='*50}\n")
    
    # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º –Ω–µ—Å–∫–æ–ª—å–∫–æ –ª—É—á—à–∏—Ö –∏ —Ö—É–¥—à–∏—Ö –ø—Ä–∏–º–µ—Ä–æ–≤
    if show_examples and len(results_data) > 0:
        print("\nüéØ –ê–ù–ê–õ–ò–ó –†–ï–ó–£–õ–¨–¢–ê–¢–û–í:")
        
        # –í—ã—á–∏—Å–ª—è–µ–º WER –¥–ª—è –∫–∞–∂–¥–æ–≥–æ —Å—ç–º–ø–ª–∞
        for result in results_data:
            result['sample_wer'] = jiwer.wer(result['reference'], result['hypothesis'])
        
        # –°–æ—Ä—Ç–∏—Ä—É–µ–º –ø–æ WER
        results_sorted = sorted(results_data, key=lambda x: x['sample_wer'])
        
        print(f"\n‚úÖ –¢–û–ü-3 –õ–£–ß–®–ò–• –†–ï–ó–£–õ–¨–¢–ê–¢–ê (—Å–∞–º—ã–π –Ω–∏–∑–∫–∏–π WER):")
        for i, result in enumerate(results_sorted[:3]):
            print(f"\nü•á #{i+1} (–°—ç–º–ø–ª {result['sample_id']}, WER: {result['sample_wer']:.4f}):")
            print(f"   –†–µ–∞–ª—å–Ω—ã–π:     {result['reference']}")
            print(f"   –¢—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ü–∏—è: {result['hypothesis']}")
        
        print(f"\n‚ùå –¢–û–ü-3 –•–£–î–®–ò–• –†–ï–ó–£–õ–¨–¢–ê–¢–ê (—Å–∞–º—ã–π –≤—ã—Å–æ–∫–∏–π WER):")
        for i, result in enumerate(results_sorted[-3:]):
            print(f"\nüíî #{i+1} (–°—ç–º–ø–ª {result['sample_id']}, WER: {result['sample_wer']:.4f}):")
            print(f"   –†–µ–∞–ª—å–Ω—ã–π:     {result['reference']}")
            print(f"   –¢—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ü–∏—è: {result['hypothesis']}")
    
    with open(output_file, 'a', encoding='utf-8') as f:
        f.write(f"{len(references)}\t{final_wer_score:.4f}\t{final_cer_score:.4f}\n")
    
    print(f"üíæ –ü—Ä–æ–º–µ–∂—É—Ç–æ—á–Ω—ã–µ –∏ —Ñ–∏–Ω–∞–ª—å–Ω—ã–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã –≤ —Ñ–∞–π–ª: {output_file}")

    print("‚úçÔ∏è  –†–∞—Å—á–µ—Ç –º–µ—Ç—Ä–∏–∫ –¥–ª—è –¥–µ—Ç–∞–ª—å–Ω–æ–≥–æ –æ—Ç—á–µ—Ç–∞...")
    results_df = pd.DataFrame(results_data)
    results_df['wer'] = results_df.apply(lambda row: jiwer.wer(row['reference'], row['hypothesis']), axis=1)
    results_df['cer'] = results_df.apply(lambda row: jiwer.cer(row['reference'], row['hypothesis']), axis=1)

    results_df.to_csv(detailed_output_file, sep='\t', index=False, encoding='utf-8')
    print(f"üíæ –î–µ—Ç–∞–ª—å–Ω—ã–π –æ—Ç—á–µ—Ç –ø–æ –∫–∞–∂–¥–æ–º—É —Å—ç–º–ø–ª—É —Å–æ—Ö—Ä–∞–Ω–µ–Ω –≤ —Ñ–∞–π–ª: {detailed_output_file}")


def main():
    parser = argparse.ArgumentParser(description=f"–ë–µ–Ω—á–º–∞—Ä–∫ –¥–ª—è –º–æ–¥–µ–ª–∏ {MODEL_NAME} ASR")
    parser.add_argument("--dataset_path", type=str, default=str(DEFAULT_DATASET_DIR), help="–ü—É—Ç—å –∫ –ø–∞–ø–∫–µ —Å –¥–∞—Ç–∞—Å–µ—Ç–æ–º")
    parser.add_argument("--model-path", type=str, default=str(DEFAULT_MODEL_PATH), help="–ü—É—Ç—å –∫ –º–æ–¥–µ–ª–∏")
    parser.add_argument("--sampling_rate", type=int, default=16000, help="–ß–∞—Å—Ç–æ—Ç–∞ –¥–∏—Å–∫—Ä–µ—Ç–∏–∑–∞—Ü–∏–∏ –∞—É–¥–∏–æ –≤ –≤–∞—à–µ–º –¥–∞—Ç–∞—Å–µ—Ç–µ.")
    parser.add_argument("--output_file", type=str, default=str(OUTPUTS_DIR / "benchmark_log.tsv"), help="–§–∞–π–ª –¥–ª—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è –ª–æ–≥–∞ —Å –ø—Ä–æ–º–µ–∂—É—Ç–æ—á–Ω—ã–º–∏ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞–º–∏.")
    parser.add_argument("--detailed_output_file", type=str, default=str(OUTPUTS_DIR / "benchmark_detailed.tsv"), help="–§–∞–π–ª –¥–ª—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è –¥–µ—Ç–∞–ª—å–Ω–æ–≥–æ –æ—Ç—á–µ—Ç–∞.")
    parser.add_argument("--max-tokens", type=int, default=256, help="–ú–∞–∫—Å. –∫–æ–ª-–≤–æ –Ω–æ–≤—ã—Ö —Ç–æ–∫–µ–Ω–æ–≤")
    parser.add_argument("--temperature", type=float, default=0.0, help="–¢–µ–º–ø–µ—Ä–∞—Ç—É—Ä–∞ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏")
    parser.add_argument("--show-examples", action="store_true", default=True, help="–ü–æ–∫–∞–∑—ã–≤–∞—Ç—å –ø—Ä–∏–º–µ—Ä—ã —Ç—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ü–∏–π")
    parser.add_argument("--show-every", type=int, default=10, help="–ü–æ–∫–∞–∑—ã–≤–∞—Ç—å –∫–∞–∂–¥—ã–π N-–π –ø—Ä–∏–º–µ—Ä")
    parser.add_argument("--no-examples", action="store_true", help="–û—Ç–∫–ª—é—á–∏—Ç—å –ø–æ–∫–∞–∑ –ø—Ä–∏–º–µ—Ä–æ–≤")
    
    args = parser.parse_args()
    
    # –ï—Å–ª–∏ —É–∫–∞–∑–∞–Ω --no-examples, –æ—Ç–∫–ª—é—á–∞–µ–º –ø–æ–∫–∞–∑ –ø—Ä–∏–º–µ—Ä–æ–≤
    show_examples = args.show_examples and not args.no_examples
    
    asr_model = Estimin3nASRInference(model_path=args.model_path)
    run_benchmark(
        asr_model=asr_model,
        dataset_path=args.dataset_path,
        source_sampling_rate=args.sampling_rate,
        max_tokens=args.max_tokens,
        temperature=args.temperature,
        output_file=args.output_file,
        detailed_output_file=args.detailed_output_file,
        show_examples=show_examples,
        show_every=args.show_every
    )


if __name__ == "__main__":
    main()
