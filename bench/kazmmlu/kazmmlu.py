############################################
###    RUN WITH TORCHDYNAMO_DISABLE=1    ###
############################################

import torch
torch._dynamo.disable()

from transformers import AutoTokenizer, AutoModelForCausalLM
import argparse
import os
from tqdm import tqdm
from datasets import load_dataset
import pandas as pd
import re
from collections import defaultdict
from pathlib import Path
from utils.config import DEFAULT_MODEL_PATH, OUTPUTS_DIR, get_device, get_dtype, MODEL_NAME, ensure_dirs


ensure_dirs()

class Estimin3nKazMMLUInference:
    def __init__(self, model_path: str | os.PathLike | None = None):
        self.model_path = str(Path(model_path).expanduser()) if model_path else str(DEFAULT_MODEL_PATH)
        self.device = get_device()
        self.dtype = get_dtype(self.device)
        print(f"üìä –£—Å—Ç—Ä–æ–π—Å—Ç–≤–æ: {self.device} | –¢–∏–ø –¥–∞–Ω–Ω—ã—Ö: {self.dtype}")

        self.model = AutoModelForCausalLM.from_pretrained(
            self.model_path, 
            trust_remote_code=True, 
            torch_dtype=self.dtype,
            device_map="auto",
            low_cpu_mem_usage=True,
            attn_implementation="eager",
        )
        
        self.tokenizer = AutoTokenizer.from_pretrained(
            self.model_path, 
            trust_remote_code=True
        )
        
        if self.tokenizer.pad_token is None:
            self.tokenizer.pad_token = self.tokenizer.eos_token
            
        self.model.eval()
    print(f"üöÄ –ú–æ–¥–µ–ª—å {MODEL_NAME} –∑–∞–≥—Ä—É–∂–µ–Ω–∞ –∏ –≥–æ—Ç–æ–≤–∞ –¥–ª—è KazMMLU!\n")

    def format_question(self, question, options, language="kazakh"):
        """–§–æ—Ä–º–∞—Ç–∏—Ä—É–µ—Ç –≤–æ–ø—Ä–æ—Å –≤ —Å—Ç–∏–ª–µ –º–Ω–æ–∂–µ—Å—Ç–≤–µ–Ω–Ω–æ–≥–æ –≤—ã–±–æ—Ä–∞"""
        if language == "kazakh":
            prompt = f"""–°“±—Ä–∞“õ: {question}

A) {options['A']}
B) {options['B']}
C) {options['C']}
D) {options['D']}
E) {options['E']}

–î“±—Ä—ã—Å –∂–∞—É–∞–ø (—Ç–µ–∫ ”ô—Ä—ñ–ø—Ç—ñ –∂–∞–∑—ã“£—ã–∑):"""
        else:
            prompt = f"""–í–æ–ø—Ä–æ—Å: {question}

A) {options['A']}
B) {options['B']}
C) {options['C']}
D) {options['D']}
E) {options['E']}

–ü—Ä–∞–≤–∏–ª—å–Ω—ã–π –æ—Ç–≤–µ—Ç (—Ç–æ–ª—å–∫–æ –±—É–∫–≤—É):"""
        
        return prompt

    def get_answer(self, prompt, max_new_tokens=5, temperature=0.1):
        """–ü–æ–ª—É—á–∞–µ—Ç –æ—Ç–≤–µ—Ç –æ—Ç –º–æ–¥–µ–ª–∏"""
        try:
            inputs = self.tokenizer(
                prompt, 
                return_tensors="pt", 
                truncation=True, 
                max_length=2048
            ).to(self.device)
            
            generation_kwargs = {
                'max_new_tokens': max_new_tokens,
                'do_sample': True if temperature > 0 else False,
                'temperature': temperature,
                'pad_token_id': self.tokenizer.eos_token_id,
                'eos_token_id': self.tokenizer.eos_token_id,
                'repetition_penalty': 1.1,
            }
            
            with torch.no_grad():
                outputs = self.model.generate(**inputs, **generation_kwargs)
            
            generated_tokens = outputs[0][inputs["input_ids"].shape[1]:]
            answer = self.tokenizer.decode(generated_tokens, skip_special_tokens=True)
            
            answer_clean = self.extract_answer_letter(answer)
            return answer_clean
            
        except Exception as e:
            print(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –æ—Ç–≤–µ—Ç–∞: {e}")
            return "N/A"

    def extract_answer_letter(self, text):
        """–ò–∑–≤–ª–µ–∫–∞–µ—Ç –±—É–∫–≤—É –æ—Ç–≤–µ—Ç–∞ –∏–∑ —Å–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–Ω–Ω–æ–≥–æ —Ç–µ–∫—Å—Ç–∞"""
        match = re.search(r'\b([ABCDE])\b', text.upper())
        if match:
            return match.group(1)
        
        clean_text = text.strip().upper()
        if clean_text and clean_text[0] in 'ABCDE':
            return clean_text[0]
            
        return "N/A"

def get_available_configs():
    """–ü–æ–ª—É—á–∞–µ—Ç —Å–ø–∏—Å–æ–∫ –¥–æ—Å—Ç—É–ø–Ω—ã—Ö –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–π KazMMLU"""
    return [
        'Accounting and Auditing (Professional & University in rus)',
        'Biology (High School in kaz)', 'Biology (High School in rus)',
        'Biology (Professional & University in rus)', 'Chemistry (High School in kaz)',
        'Chemistry (High School in rus)', 'Culture and Art (Professional & University in rus)',
        'Economics and Entrepreneurship (Professional in rus)',
        'Education and Training (Professional & University in rus)',
        'Finance (Professional & University in rus)',
        'General Education Disciplines (Professional & University in rus)',
        'Geography (High School in kaz)', 'Geography (High School in rus)',
        'Informatics (High School in kaz)', 'Informatics (High School in rus)',
        'Jurisprudence (Professional & University in rus)',
        'Kazakh History (High School in kaz)', 'Kazakh History (High School in rus)',
        'Kazakh Language (High School in kaz)', 'Kazakh Literature (High School in kaz)',
        'Law (High School in kaz)', 'Law (High School in rus)',
        'Management and Marketing (Professional & University in rus)',
        'Math (High School in kaz)', 'Math (High School in rus)',
        'Math Literacy (High School in rus)', 'Medicine (Professional & University in rus)',
        'Philosophy and Psychology (Professional & University in rus)',
        'Physics (High School in kaz)', 'Physics (High School in rus)',
        'Reading Literacy (High School in kaz)', 'Reading Literacy (High School in rus)',
        'Russian Language (High School in rus)', 'Russian Literature (High School in rus)',
        'Social Science (Professional & University in rus)',
        'World History (High School in kaz)', 'World History (High School in rus)'
    ]

def print_sample_comparison(sample_num, question, options, correct_answer, predicted_answer, 
                          subject, level, is_correct):
    """–ö—Ä–∞—Å–∏–≤—ã–π –≤—ã–≤–æ–¥ —Å—Ä–∞–≤–Ω–µ–Ω–∏—è –¥–ª—è –æ—Ç–¥–µ–ª—å–Ω–æ–≥–æ –≤–æ–ø—Ä–æ—Å–∞"""
    status = "‚úÖ –ü–†–ê–í–ò–õ–¨–ù–û" if is_correct else "‚ùå –ù–ï–ü–†–ê–í–ò–õ–¨–ù–û"
    print(f"\n{'='*100}")
    print(f"üìù –û–ë–†–ê–ó–ï–¶ #{sample_num} | {subject} ({level}) | {status}")
    print(f"{'='*100}")
    print(f"‚ùì –í–û–ü–†–û–°:")
    print(f"   {question}")
    print(f"\nüìã –í–ê–†–ò–ê–ù–¢–´ –û–¢–í–ï–¢–û–í:")
    for letter in ['A', 'B', 'C', 'D', 'E']:
        marker = "üëâ" if predicted_answer == letter else "  "
        correct_marker = "‚≠ê" if correct_answer == letter else "  "
        print(f"   {marker} {correct_marker} {letter}) {options[letter]}")
    
    print(f"\nüéØ –ü–†–ê–í–ò–õ–¨–ù–´–ô –û–¢–í–ï–¢: {correct_answer}")
    print(f"ü§ñ –û–¢–í–ï–¢ –ú–û–î–ï–õ–ò:     {predicted_answer}")
    print(f"{'='*100}")

def run_kazmlu_benchmark(model, max_tokens=5, temperature=0.1, 
                        output_file=None, 
                        detailed_output_file=None,
                        show_examples=True, show_every=50, subset_names=None,
                        run_all_configs=True):
    output_file = str(OUTPUTS_DIR / "kazmlu_results.tsv") if output_file is None else output_file
    detailed_output_file = str(OUTPUTS_DIR / "kazmlu_detailed.tsv") if detailed_output_file is None else detailed_output_file
    
    # –û–ø—Ä–µ–¥–µ–ª—è–µ–º –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏ –¥–ª—è –∑–∞–ø—É—Å–∫–∞
    if subset_names:
        configs_to_run = subset_names if isinstance(subset_names, list) else [subset_names]
    elif run_all_configs:
        configs_to_run = get_available_configs()
    else:
        print("‚ùå –ù–µ —É–∫–∞–∑–∞–Ω—ã –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏ –¥–ª—è –∑–∞–ø—É—Å–∫–∞")
        return None

    print(f"üîÑ –ë—É–¥–µ—Ç –∑–∞–ø—É—â–µ–Ω–æ {len(configs_to_run)} –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–π:")
    for i, config in enumerate(configs_to_run[:5], 1):
        print(f"   {i}. {config}")
    if len(configs_to_run) > 5:
        print(f"   ... –∏ –µ—â—ë {len(configs_to_run) - 5} –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–π")

    all_results_data = []
    total_correct = 0
    total_questions = 0
    config_stats = {}
    
    with open(output_file, 'w', encoding='utf-8') as f:
        f.write("config\tsample_count\taccuracy\tcorrect\ttotal\n")
        
        for config_idx, config_name in enumerate(configs_to_run):
            print(f"\n{'='*100}")
            print(f"üìö –û–ë–†–ê–ë–û–¢–ö–ê –ö–û–ù–§–ò–ì–£–†–ê–¶–ò–ò {config_idx + 1}/{len(configs_to_run)}")
            print(f"üìñ {config_name}")
            print(f"{'='*100}")
            
            try:
                # –ó–∞–≥—Ä—É–∂–∞–µ–º –∫–æ–Ω–∫—Ä–µ—Ç–Ω—É—é –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—é
                dataset = load_dataset("MBZUAI/KazMMLU", config_name)['test']
                print(f"‚úÖ –ó–∞–≥—Ä—É–∂–µ–Ω–æ {len(dataset)} –≤–æ–ø—Ä–æ—Å–æ–≤")
            except Exception as e:
                print(f"‚ùå –û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏ '{config_name}': {e}")
                continue

            if len(dataset) == 0:
                print(f"‚ö†Ô∏è –ü—É—Å—Ç–∞—è –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è: {config_name}")
                continue

            config_correct = 0
            config_total = 0
            
            for i, sample in enumerate(tqdm(dataset, desc=f"üß† {config_name[:30]}...")):
                try:
                    # –ò–∑–≤–ª–µ–∫–∞–µ–º –¥–∞–Ω–Ω—ã–µ
                    question = sample['Question']
                    options = {
                        'A': sample['Option A'],
                        'B': sample['Option B'], 
                        'C': sample['Option C'],
                        'D': sample['Option D'],
                        'E': sample['Option E']
                    }
                    correct_answer = sample['Answer Key']
                    subject = sample.get('Subject', config_name)
                    level = sample.get('Level', 'Unknown')
                    language = "kazakh" if sample.get('Language') == "Kazakh" else "russian"
                    
                    # –§–æ—Ä–º–∞—Ç–∏—Ä—É–µ–º –ø—Ä–æ–º–ø—Ç
                    prompt = model.format_question(question, options, language)
                    
                    # –ü–æ–ª—É—á–∞–µ–º –æ—Ç–≤–µ—Ç –º–æ–¥–µ–ª–∏
                    predicted_answer = model.get_answer(
                        prompt, 
                        max_new_tokens=max_tokens, 
                        temperature=temperature
                    )
                    
                    # –ü—Ä–æ–≤–µ—Ä—è–µ–º –ø—Ä–∞–≤–∏–ª—å–Ω–æ—Å—Ç—å
                    is_correct = predicted_answer == correct_answer
                    if is_correct:
                        config_correct += 1
                        total_correct += 1
                    config_total += 1
                    total_questions += 1
                    
                    # –°–æ—Ö—Ä–∞–Ω—è–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç
                    all_results_data.append({
                        'config': config_name,
                        'sample_id': i + 1,
                        'question': question,
                        'correct_answer': correct_answer,
                        'predicted_answer': predicted_answer,
                        'is_correct': is_correct,
                        'subject': subject,
                        'level': level,
                        'language': language
                    })
                    
                    # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º –ø—Ä–∏–º–µ—Ä—ã
                    if show_examples and ((i + 1) % show_every == 0 or i == 0):
                        print_sample_comparison(
                            i + 1, question, options, correct_answer, 
                            predicted_answer, subject, level, is_correct
                        )
                    
                except Exception as e:
                    print(f"‚ùå –û—à–∏–±–∫–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏ –≤–æ–ø—Ä–æ—Å–∞ {i+1} –≤ {config_name}: {e}")
                    continue
            
            # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –ø–æ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏
            config_accuracy = config_correct / config_total if config_total > 0 else 0
            config_stats[config_name] = {
                'correct': config_correct,
                'total': config_total,
                'accuracy': config_accuracy
            }
            
            print(f"\nüìä –†–ï–ó–£–õ–¨–¢–ê–¢ –ö–û–ù–§–ò–ì–£–†–ê–¶–ò–ò '{config_name}':")
            print(f"   –¢–æ—á–Ω–æ—Å—Ç—å: {config_accuracy:.4f} ({config_accuracy*100:.2f}%)")
            print(f"   –ü—Ä–∞–≤–∏–ª—å–Ω—ã—Ö: {config_correct}/{config_total}")
            
            # –°–æ—Ö—Ä–∞–Ω—è–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏
            f.write(f"{config_name}\t{config_total}\t{config_accuracy:.4f}\t{config_correct}\t{config_total}\n")
            f.flush()

    # –§–∏–Ω–∞–ª—å–Ω—ã–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã
    overall_accuracy = total_correct / total_questions if total_questions > 0 else 0
    
    print(f"\n{'='*100}")
    print("üèÜ –§–ò–ù–ê–õ–¨–ù–´–ï –†–ï–ó–£–õ–¨–¢–ê–¢–´ KazMMLU")
    print(f"{'='*100}")
    print(f"üìä –í—Å–µ–≥–æ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–π:    {len(config_stats)}")
    print(f"üìä –í—Å–µ–≥–æ –≤–æ–ø—Ä–æ—Å–æ–≤:        {total_questions}")
    print(f"‚úÖ –ü—Ä–∞–≤–∏–ª—å–Ω—ã—Ö –æ—Ç–≤–µ—Ç–æ–≤:    {total_correct}")
    print(f"‚ùå –ù–µ–ø—Ä–∞–≤–∏–ª—å–Ω—ã—Ö –æ—Ç–≤–µ—Ç–æ–≤:  {total_questions - total_correct}")
    print(f"üéØ **–û–ë–©–ê–Ø –¢–û–ß–ù–û–°–¢–¨: {overall_accuracy:.4f} ({overall_accuracy*100:.2f}%)**")
    print(f"{'='*100}")
    
    # –¢–û–ü –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–π
    print(f"\nüìà –¢–û–ü-10 –õ–£–ß–®–ò–• –ö–û–ù–§–ò–ì–£–†–ê–¶–ò–ô:")
    sorted_configs = sorted(config_stats.items(), key=lambda x: x[1]['accuracy'], reverse=True)
    for i, (config, stats) in enumerate(sorted_configs[:10], 1):
        print(f"   {i:2d}. {stats['accuracy']:.3f} ({stats['accuracy']*100:.1f}%) | {config}")
    
    print(f"\nüìâ –¢–û–ü-5 –•–£–î–®–ò–• –ö–û–ù–§–ò–ì–£–†–ê–¶–ò–ô:")
    for i, (config, stats) in enumerate(sorted_configs[-5:], 1):
        print(f"   {i:2d}. {stats['accuracy']:.3f} ({stats['accuracy']*100:.1f}%) | {config}")
    
    # –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ —Ñ–∏–Ω–∞–ª—å–Ω—ã—Ö —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
    with open(output_file, 'a', encoding='utf-8') as f:
        f.write(f"OVERALL\t{total_questions}\t{overall_accuracy:.4f}\t{total_correct}\t{total_questions}\n")
    
    # –î–µ—Ç–∞–ª—å–Ω—ã–π –æ—Ç—á–µ—Ç
    results_df = pd.DataFrame(all_results_data)
    results_df.to_csv(detailed_output_file, sep='\t', index=False, encoding='utf-8')
    
    print(f"\nüíæ –†–µ–∑—É–ª—å—Ç–∞—Ç—ã —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã:")
    print(f"   –û—Å–Ω–æ–≤–Ω–æ–π –ª–æ–≥: {output_file}")
    print(f"   –î–µ—Ç–∞–ª—å–Ω—ã–π –æ—Ç—á–µ—Ç: {detailed_output_file}")
    
    return overall_accuracy

def main():
    parser = argparse.ArgumentParser(description=f"–ë–µ–Ω—á–º–∞—Ä–∫ {MODEL_NAME} –Ω–∞ KazMMLU")
    parser.add_argument("--model-path", type=str, default=str(DEFAULT_MODEL_PATH), 
                       help="–ü—É—Ç—å –∫ –º–æ–¥–µ–ª–∏")
    parser.add_argument("--subset", type=str, default=None, 
                       help="–ö–æ–Ω–∫—Ä–µ—Ç–Ω–æ–µ –ø–æ–¥–º–Ω–æ–∂–µ—Å—Ç–≤–æ –¥–ª—è —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è")
    parser.add_argument("--run-all", action="store_true", default=True,
                       help="–ó–∞–ø—É—Å—Ç–∏—Ç—å –≤—Å–µ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏ (–ø–æ —É–º–æ–ª—á–∞–Ω–∏—é)")
    parser.add_argument("--kazakh-only", action="store_true",
                       help="–¢–æ–ª—å–∫–æ –∫–∞–∑–∞—Ö—Å–∫–∏–µ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏")
    parser.add_argument("--russian-only", action="store_true", 
                       help="–¢–æ–ª—å–∫–æ —Ä—É—Å—Å–∫–∏–µ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏")
    parser.add_argument("--output_file", type=str, default="kazmlu_benchmark.tsv", 
                       help="–§–∞–π–ª –¥–ª—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤")
    parser.add_argument("--detailed_output_file", type=str, default="kazmlu_detailed.tsv", 
                       help="–§–∞–π–ª –¥–ª—è –¥–µ—Ç–∞–ª—å–Ω–æ–≥–æ –æ—Ç—á–µ—Ç–∞")
    parser.add_argument("--max-tokens", type=int, default=5, 
                       help="–ú–∞–∫—Å. –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –Ω–æ–≤—ã—Ö —Ç–æ–∫–µ–Ω–æ–≤")
    parser.add_argument("--temperature", type=float, default=0.1, 
                       help="–¢–µ–º–ø–µ—Ä–∞—Ç—É—Ä–∞ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏")
    parser.add_argument("--show-examples", action="store_true", default=True, 
                       help="–ü–æ–∫–∞–∑—ã–≤–∞—Ç—å –ø—Ä–∏–º–µ—Ä—ã –≤–æ–ø—Ä–æ—Å–æ–≤ –∏ –æ—Ç–≤–µ—Ç–æ–≤")
    parser.add_argument("--show-every", type=int, default=50, 
                       help="–ü–æ–∫–∞–∑—ã–≤–∞—Ç—å –∫–∞–∂–¥—ã–π N-–π –ø—Ä–∏–º–µ—Ä")
    parser.add_argument("--no-examples", action="store_true", 
                       help="–û—Ç–∫–ª—é—á–∏—Ç—å –ø–æ–∫–∞–∑ –ø—Ä–∏–º–µ—Ä–æ–≤")
    
    args = parser.parse_args()
    
    # –û–ø—Ä–µ–¥–µ–ª—è–µ–º –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏ –¥–ª—è –∑–∞–ø—É—Å–∫–∞
    subset_names = None
    run_all = True
    
    if args.subset:
        subset_names = [args.subset]
        run_all = False
    elif args.kazakh_only:
        subset_names = [config for config in get_available_configs() if "in kaz)" in config]
        run_all = False
    elif args.russian_only:
        subset_names = [config for config in get_available_configs() if "in rus)" in config]
        run_all = False
    
    show_examples = args.show_examples and not args.no_examples
    
    print(f"üöÄ –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –º–æ–¥–µ–ª–∏ {MODEL_NAME} –¥–ª—è KazMMLU...")
    model = Estimin3nKazMMLUInference(model_path=args.model_path)
    
    accuracy = run_kazmlu_benchmark(
        model=model,
        max_tokens=args.max_tokens,
        temperature=args.temperature,
        output_file=args.output_file,
        detailed_output_file=args.detailed_output_file,
        show_examples=show_examples,
        show_every=args.show_every,
        subset_names=subset_names,
        run_all_configs=run_all
    )
    
    if accuracy is not None:
        print(f"\nüéä –ë–µ–Ω—á–º–∞—Ä–∫ –∑–∞–≤–µ—Ä—à–µ–Ω! –ò—Ç–æ–≥–æ–≤–∞—è —Ç–æ—á–Ω–æ—Å—Ç—å: {accuracy:.4f} ({accuracy*100:.2f}%)")
    else:
        print(f"\nüíî –ë–µ–Ω—á–º–∞—Ä–∫ –∑–∞–≤–µ—Ä—à–µ–Ω —Å –æ—à–∏–±–∫–∞–º–∏")

if __name__ == "__main__":
    main()
